"""
Stage 4 Smoke Test: Structured Extraction Pipeline
Validates the Definition of Done:
  - Run extraction on a note → objects contain "Claims" and "Ideas"
  - object_mentions link objects back to source spans
  - Pydantic validation catches bad data

Run: python test_extraction.py
"""
import os
from dotenv import load_dotenv

load_dotenv()

from ml.extraction import LLMExtractor, ExtractionResult, _attempt_json_repair


def test_json_repair():
    """Test the JSON repair logic handles common LLM mistakes."""
    print("\n── Test: JSON Repair Logic ──")

    # Case 1: Markdown fences
    fenced = '```json\n{"objects": [], "links": []}\n```'
    result = _attempt_json_repair(fenced)
    assert result is not None, "Failed to strip markdown fences"
    print("  ✓ Strips markdown fences")

    # Case 2: Trailing commas
    trailing = '{"objects": [{"id": "obj_001", "type": "Claim",},], "links": []}'
    result = _attempt_json_repair(trailing)
    assert result is not None, "Failed to fix trailing commas"
    print("  ✓ Fixes trailing commas")

    # Case 3: Valid JSON passes through
    valid = '{"objects": [], "links": []}'
    result = _attempt_json_repair(valid)
    assert result == {"objects": [], "links": []}, "Valid JSON should pass through"
    print("  ✓ Valid JSON passes through")

    # Case 4: Truly broken JSON returns None
    broken = 'this is not json at all {'
    result = _attempt_json_repair(broken)
    assert result is None, "Broken JSON should return None"
    print("  ✓ Irrecoverable JSON returns None")


def test_pydantic_validation():
    """Test Pydantic models enforce the schema."""
    print("\n── Test: Pydantic Validation ──")

    # Valid extraction result
    valid_data = {
        "objects": [{
            "id": "obj_001",
            "type": "Claim",
            "canonical_text": "Test claim",
            "confidence": 0.9,
            "context": "Test context",
            "span_start": 0,
            "span_end": 10,
        }],
        "links": []
    }
    result = ExtractionResult(**valid_data)
    assert len(result.objects) == 1
    assert result.objects[0].type == "Claim"
    print("  ✓ Valid data accepted")

    # Confidence clamping
    clamped_data = {
        "objects": [{
            "id": "obj_002",
            "type": "Idea",
            "canonical_text": "Test idea",
            "confidence": 1.5,  # Should be clamped to 1.0
        }],
        "links": []
    }
    result = ExtractionResult(**clamped_data)
    assert result.objects[0].confidence == 1.0
    print("  ✓ Confidence clamped to [0, 1]")

    # Invalid type raises error
    try:
        bad_data = {
            "objects": [{
                "id": "obj_003",
                "type": "InvalidType",
                "canonical_text": "Bad",
                "confidence": 0.5,
            }],
            "links": []
        }
        ExtractionResult(**bad_data)
        assert False, "Should have raised validation error"
    except Exception:
        print("  ✓ Invalid type rejected by Pydantic")


def test_llm_extraction():
    """Test the full LLM extraction pipeline (Definition of Done)."""
    print("\n── Test: LLM Extraction Pipeline ──")

    # Verify API key
    api_key = os.getenv("GROQ_API_KEY")
    if not api_key:
        print("  ✗ GROQ_API_KEY not set. Skipping LLM test.")
        return False

    print(f"  ✓ API key loaded (ends in ...{api_key[-4:]})")

    extractor = LLMExtractor()
    print(f"  ✓ LLMExtractor initialized (model={extractor.model})")

    # Test passage (designed to produce Claims AND Ideas)
    test_text = """Photosynthesis is the process by which plants convert sunlight into energy.
This process requires water and carbon dioxide.
Some researchers question whether artificial photosynthesis could replace solar panels.
Key idea: Bio-inspired solar cells could be the next breakthrough in renewable energy.
Task: Review the latest papers on artificial photosynthesis efficiency.
Assumption: Current solar panel technology has reached a performance plateau."""

    print(f"\n  ── Input Text ──")
    print(f"  {test_text.strip()}")
    print(f"  ── End Input ──\n")

    # Extract
    result = extractor.extract(test_text, note_id="note_test_001", span_id="span_test_001")

    # ══ DEFINITION OF DONE CHECKS ══

    # Check 1: Objects table has rows
    print(f"\n  ── Objects Table ({len(result.objects)} rows) ──")
    type_set = set()
    for obj in result.objects:
        type_set.add(obj.type)
        span_info = f"[{obj.span_start}:{obj.span_end}]" if obj.span_start is not None else "[no span]"
        print(f"    {obj.id} | {obj.type:12s} | \"{obj.canonical_text[:50]}\" | conf={obj.confidence} | {span_info}")

    # Check 2: Must contain both Claims AND Ideas
    assert 'Claim' in type_set or 'Evidence' in type_set, \
        f"Expected at least one Claim or Evidence! Got types: {type_set}"
    assert 'Idea' in type_set or 'Question' in type_set, \
        f"Expected at least one Idea or Question! Got types: {type_set}"
    print(f"\n  ✓ PASSED: Objects contain Claims/Evidence AND Ideas/Questions")

    # Check 3: Links table
    print(f"\n  ── Links Table ({len(result.links)} rows) ──")
    for link in result.links:
        print(f"    {link.source_id} --[{link.type}]--> {link.target_id} (conf={link.confidence})")

    # Check 4: Object mentions (provenance linking)
    print(f"\n  ── Object Mentions ({len(result.mentions)} rows) ──")
    for m in result.mentions:
        print(f"    {m.object_id} → note={m.note_id}, span={m.span_id}, role={m.role}")
    assert len(result.mentions) == len(result.objects), \
        "Every object should have a mention linking it to the source span"
    assert all(m.note_id == "note_test_001" for m in result.mentions), \
        "All mentions should reference the correct note_id"
    print(f"  ✓ PASSED: Object mentions correctly link to source span")

    return True


def main():
    print("=" * 60)
    print("  STAGE 4 EXTRACTION — SMOKE TEST")
    print("=" * 60)

    # Offline tests (no API needed)
    test_json_repair()
    test_pydantic_validation()

    # Online test (requires GROQ_API_KEY)
    llm_passed = test_llm_extraction()

    print("\n" + "=" * 60)
    if llm_passed:
        print("  ✓ ALL TESTS PASSED — Stage 4 Definition of Done verified!")
    else:
        print("  ⚠ Offline tests passed. Skipped LLM test (no API key).")
    print("=" * 60)


if __name__ == "__main__":
    main()
